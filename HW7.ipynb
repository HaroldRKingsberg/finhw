{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fmt\n",
    "import itertools\n",
    "\n",
    "from sobol_seq import i4_sobol_generate\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Set 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This homework is to price [synthetic CDO](https://en.wikipedia.org/wiki/Synthetic_CDO) using the one factor Gaussian Copula model. \n",
    "\n",
    "A synthetic CDO consists of $n$ CDS, the total loss of the portfolio is defned as:\n",
    "\n",
    "$$ l(t) = \\sum_i^n w_i \\tilde {\\mathbb{1}}_i(t) (1-r_i(t)) $$\n",
    "\n",
    "where $w_i$ and $r_i(t)$ are the notional weights and recovery rate of the i-th name in the portfolio. The notional weighs sum up to 1: $\\sum_i w_i = 1 $. The $ \\tilde {\\mathbb{1}}_i(t) $ is the default indicator of the i-th name defaulted before time $t$, the default probability is therefore $p_i(t) = \\mathbb E[\\tilde {\\mathbb{1}}_i(t) ]$\n",
    "\n",
    "For the purpose of this homework, we consider a simplified synthetic CDO that has no coupon payments, therefore the PV of a \\$1 notional synthetic CDO tranche with maturity $t$, attachment $a$ and detachment $d$ is:\n",
    "\n",
    "$$ v(a, d) = \\frac{d(t)}{d-a} \\min\\left((l(t) - a)^+, d-a\\right) $$\n",
    "\n",
    "where $d(t)$ is the discount factor.\n",
    "\n",
    "The following are the parameters to the synthetic CDO, and a straight forward Monte Carlo pricer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "portfolio expected loss is  0.04417871571857583\n"
     ]
    }
   ],
   "source": [
    "n = 125\n",
    "t = 5.\n",
    "defProbs = 1 - exp(-(np.random.uniform(size=n)*.03)*t)\n",
    "recovery = 0.4*np.ones(n)\n",
    "w = 1./n*np.ones(n)\n",
    "rho = 0.5\n",
    "discf = .9\n",
    "npath = 1000\n",
    "\n",
    "# a list of attachements and detachements, they pair up by elements\n",
    "attachements = np.array([0, .03, .07, .1, .15, .3])\n",
    "detachements = np.array([.03, .07, .1, .15, .3, .6])\n",
    "\n",
    "#portfolio expected loss\n",
    "el = np.sum(w*defProbs*(1-recovery))\n",
    "print(\"portfolio expected loss is \", el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "class CDO(object) :\n",
    "    def __init__(self, w, defProbs, recovery, a, d) :\n",
    "        self.w = w/np.sum(w)\n",
    "        self.p = defProbs\n",
    "        self.rec = recovery\n",
    "        self.rho = rho\n",
    "        self.a = a\n",
    "        self.d = d\n",
    "\n",
    "    def drawDefaultIndicator(self, z, rho) :\n",
    "        '''return a list of default indicators given common factor z, using one factor Gaussian Copula\n",
    "        '''\n",
    "        e = np.random.normal(size=np.shape(self.p))\n",
    "        x = z*np.sqrt(self.rho) + np.sqrt(1-self.rho)*e\n",
    "        return np.less(norm.cdf(x), self.p)\n",
    "\n",
    "    def portfolioLoss(self, defIndicator) :\n",
    "        '''compute portfolio loss given default indicators'''\n",
    "        return np.sum(defIndicator*self.w*(1-self.rec))\n",
    "\n",
    "    def tranchePV(self, portfLoss, discf) :\n",
    "        '''compute tranche PV from portfolio loss\n",
    "        Args:\n",
    "            portfLoss: the total portfolio loss\n",
    "            discf: discount factor\n",
    "        Returns:\n",
    "            tranche PVs'''\n",
    "        \n",
    "        sz = self.d - self.a\n",
    "        return discf/sz*np.minimum(np.maximum(portfLoss - self.a, 0), sz)\n",
    "\n",
    "    def drawPV(self, z, rho, discf) :\n",
    "        ''' compute PV and portfolio Loss conditioned on a common factor z'''\n",
    "        di = self.drawDefaultIndicator(z, rho)\n",
    "        pfLoss = self.portfolioLoss(di)\n",
    "        return self.tranchePV(pfLoss, discf), pfLoss\n",
    "    \n",
    "    \n",
    "cdo = CDO(w, defProbs, recovery, attachements, detachements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_normal_sample = np.array([])\n",
    "antithetic_sample = np.array([])\n",
    "importance_sample = np.array([])\n",
    "sobol_sample = np.array([])\n",
    "stratified_sample = np.array([])\n",
    "\n",
    "def showReductionTable(reductionSample, vanillaSample):\n",
    "    def calculatePopulationVariance(sample):\n",
    "        return sample.std() * n/(n-1)\n",
    "\n",
    "    var_r = calculatePopulationVariance(reductionSample)\n",
    "    var_p = calculatePopulationVariance(vanillaSample)\n",
    "    columns = [\n",
    "        '$\\sigma^2_{reduction}$',\n",
    "        '$\\sigma^2_{original}$',\n",
    "        '$\\sigma^2_r/\\sigma^2_o$'\n",
    "    ]\n",
    "    fmt.displayDF(pd.DataFrame([[var_r, var_p, var_r/var_p]], columns=columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularNormal(n_paths):\n",
    "    global regular_normal_sample\n",
    "    regular_normal_sample = np.random.normal(size=[n_paths])\n",
    "    return regular_normal_sample\n",
    "\n",
    "def simCDO(cdo, rho, disc, paths, z_creator):\n",
    "    zs = z_creator(paths)\n",
    "    pv = np.zeros(np.shape(cdo.a))\n",
    "    pv2 = np.zeros(np.shape(cdo.d))\n",
    "    for z in zs:\n",
    "        thisPV, _ = cdo.drawPV(z, rho, discf)\n",
    "        pv += thisPV\n",
    "        pv2 += thisPV*thisPV\n",
    "        \n",
    "    v = pv/paths\n",
    "    var = pv2/paths - v**2\n",
    "    return pv/paths, np.sqrt(var/paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<center><font size=2><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Attach</th>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Detach</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PV</th>\n",
       "      <td>0.4654</td>\n",
       "      <td>0.2388</td>\n",
       "      <td>0.1468</td>\n",
       "      <td>0.0825</td>\n",
       "      <td>0.0261</td>\n",
       "      <td>0.001613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MC err</th>\n",
       "      <td>0.01218</td>\n",
       "      <td>0.01165</td>\n",
       "      <td>0.01005</td>\n",
       "      <td>0.007677</td>\n",
       "      <td>0.003952</td>\n",
       "      <td>0.0006624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></font></center>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pv_0, err_0 = simCDO(cdo, rho, discf, npath, regularNormal)\n",
    "basic_df = pd.DataFrame(np.array([cdo.a, cdo.d, pv_0, err_0]), index=['Attach', 'Detach', 'PV', 'MC err'])\n",
    "fmt.displayDF(basic_df, fmt='4g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "Modify the simCDO function to implement the following variance reduction techniques, and show whether the technique is effective:\n",
    "\n",
    "For this homework, we only apply the variance reduction in the common market factor $z$, you should not change the random number $e$ that were drew with in the drawDefaultIndicator function, i.e., only modify the simCDO code, re-use but do not modify the CDO class. Unless explicitly mentioned, keep the simulation path the same as the base case above.\n",
    "\n",
    "Compute the **variance** reduction factor for each technique, and comment on the effectiveness of these variance reduction techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anti-thetic variate\n",
    "Reduce the number of paths by half to account for the 2x increase in computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9448453599849075\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<center><font size=2><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Attach</th>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Detach</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PV</th>\n",
       "      <td>0.4638</td>\n",
       "      <td>0.2394</td>\n",
       "      <td>0.1393</td>\n",
       "      <td>0.08626</td>\n",
       "      <td>0.02853</td>\n",
       "      <td>0.001649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MC err</th>\n",
       "      <td>0.01211</td>\n",
       "      <td>0.01164</td>\n",
       "      <td>0.009861</td>\n",
       "      <td>0.007853</td>\n",
       "      <td>0.004124</td>\n",
       "      <td>0.0006156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></font></center>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<center><font size=2><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$\\sigma^2_{reduction}$</th>\n",
       "      <th>$\\sigma^2_{original}$</th>\n",
       "      <th>$\\sigma^2_r/\\sigma^2_o$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9525</td>\n",
       "      <td>0.9620</td>\n",
       "      <td>0.9901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></font></center>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def antitheticNormal(n_paths):\n",
    "    x = np.random.normal(size=[n_paths//2])\n",
    "    global antithetic_sample\n",
    "    antithetic_sample = np.append(x, -x)\n",
    "    return antithetic_sample\n",
    "\n",
    "pv_a, err_a = simCDO(cdo, rho, discf, npath, antitheticNormal)\n",
    "antithetic_df = pd.DataFrame(np.array([cdo.a, cdo.d, pv_a, err_a]), index=['Attach', 'Detach', 'PV', 'MC err'])\n",
    "fmt.displayDF(antithetic_df, fmt='4g')\n",
    "showReductionTable(antithetic_sample, regular_normal_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that the reduction in variance here is going to be nil: Gaussian distributions are symmetric across zero. We'll save time in generating the normal random samples, but since this is a very cheap process in the first place, it's probably not worthwhile. Unsurprisingly, MC error is not appreciably different for doing this, and the estimates of PV aren't, either."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importance sampling\n",
    "Shift $z$ by -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<center><font size=2><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Attach</th>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Detach</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PV</th>\n",
       "      <td>0.4579</td>\n",
       "      <td>0.2547</td>\n",
       "      <td>0.1525</td>\n",
       "      <td>0.09378</td>\n",
       "      <td>0.03469</td>\n",
       "      <td>0.003175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MC err</th>\n",
       "      <td>0.009668</td>\n",
       "      <td>0.006902</td>\n",
       "      <td>0.005401</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.001813</td>\n",
       "      <td>0.0003007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></font></center>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<center><font size=2><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$\\sigma^2_{reduction}$</th>\n",
       "      <th>$\\sigma^2_{original}$</th>\n",
       "      <th>$\\sigma^2_r/\\sigma^2_o$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0297</td>\n",
       "      <td>0.9620</td>\n",
       "      <td>1.0704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></font></center>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def importanceSampler(n_paths, u=-1):\n",
    "    global importance_sample\n",
    "    importance_sample = np.random.normal(size=[n_paths]) + u\n",
    "    return importance_sample\n",
    "\n",
    "\n",
    "def importanceSimCDO(cdo, rho, disc, paths, u=-1):\n",
    "    zs = importanceSampler(paths, u)\n",
    "    rn_deriv = np.exp(-u*zs + .5*u*u)\n",
    "    pv = np.zeros(np.shape(cdo.a))\n",
    "    pv2 = np.zeros(np.shape(cdo.d))\n",
    "    for rn, z in zip(rn_deriv, zs):\n",
    "        thisPV, _ = cdo.drawPV(z, rho, discf)\n",
    "        thisPV *= rn\n",
    "        pv += thisPV\n",
    "        pv2 += thisPV*thisPV\n",
    "        \n",
    "    v = pv/paths\n",
    "    var = pv2/paths - v**2\n",
    "    return pv/paths, np.sqrt(var/paths)\n",
    "\n",
    "pv_i, err_i = importanceSimCDO(cdo, rho, discf, npath)\n",
    "importance_df = pd.DataFrame(np.array([cdo.a, cdo.d, pv_i, err_i]), index=['Attach', 'Detach', 'PV', 'MC err'])\n",
    "fmt.displayDF(importance_df, fmt='4g')\n",
    "showReductionTable(importance_sample, regular_normal_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, our estimate of the population variance has actually _increased_. However, our estimates are getting more precise, with the Monte Carlo error dropping noticeably over the other estimates, dropping by about 25%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobol Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Sobol sequence exists to efficiently cover a given space. However, we need to use a normal distribution to get our numbers. The best way of going about this is to use a Sobol sequence to slam out the \"random\" numbers in the interval $[0, 1]$, and then use the inverse CDF function to get normally distributed values from that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<center><font size=2><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Attach</th>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Detach</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PV</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0.2487</td>\n",
       "      <td>0.1583</td>\n",
       "      <td>0.09936</td>\n",
       "      <td>0.03552</td>\n",
       "      <td>0.002441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MC err</th>\n",
       "      <td>0.01218</td>\n",
       "      <td>0.01193</td>\n",
       "      <td>0.01045</td>\n",
       "      <td>0.008404</td>\n",
       "      <td>0.004734</td>\n",
       "      <td>0.0008294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></font></center>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<center><font size=2><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$\\sigma^2_{reduction}$</th>\n",
       "      <th>$\\sigma^2_{original}$</th>\n",
       "      <th>$\\sigma^2_r/\\sigma^2_o$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9620</td>\n",
       "      <td>1.0395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></font></center>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sobolSampler(n_paths):\n",
    "    global sobol_sample\n",
    "    sobol_sample = norm.ppf(i4_sobol_generate(1, n_paths).T[0])\n",
    "    return sobol_sample\n",
    "\n",
    "pv_sobol, err_sobol = simCDO(cdo, rho, discf, npath, sobolSampler)\n",
    "sobol_df = pd.DataFrame(np.array([cdo.a, cdo.d, pv_sobol, err_sobol]), index=['Attach', 'Detach', 'PV', 'MC err'])\n",
    "\n",
    "fmt.displayDF(sobol_df, fmt='4g')\n",
    "showReductionTable(sobol_sample, regular_normal_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do see a slight reduction in variance here. The reason for this is fairly obvious: the Sobol sequence more accurately represents the population than does raw random sampling. Still, no real change in effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified sampling\n",
    "Sample $z$ using an equal sized grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<center><font size=2><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Attach</th>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Detach</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PV</th>\n",
       "      <td>0.4673</td>\n",
       "      <td>0.2462</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.09675</td>\n",
       "      <td>0.03663</td>\n",
       "      <td>0.003132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MC err</th>\n",
       "      <td>0.01224</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.01031</td>\n",
       "      <td>0.008397</td>\n",
       "      <td>0.004749</td>\n",
       "      <td>0.0009242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></font></center>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<center><font size=2><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$\\sigma^2_{reduction}$</th>\n",
       "      <th>$\\sigma^2_{original}$</th>\n",
       "      <th>$\\sigma^2_r/\\sigma^2_o$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0054</td>\n",
       "      <td>0.9620</td>\n",
       "      <td>1.0452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></font></center>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def stratifySampler(n_paths, n_buckets=None):\n",
    "    n_buckets = float(n_buckets or n_paths//2)\n",
    "    global stratified_sample\n",
    "    stratified_sample = norm.ppf(np.array([\n",
    "        (i + x)/n_buckets \n",
    "        for i, x in zip(itertools.cycle(np.arange(n_buckets)),\n",
    "                        np.random.uniform(size=n_paths))\n",
    "    ]))\n",
    "    return stratified_sample\n",
    "\n",
    "pv_strat, err_strat = simCDO(cdo, rho, discf, npath, stratifySampler)\n",
    "strat_df = pd.DataFrame(np.array([cdo.a, cdo.d, pv_strat, err_strat]), index=['Attach', 'Detach', 'PV', 'MC err'])\n",
    "fmt.displayDF(strat_df, fmt='4g')\n",
    "showReductionTable(stratified_sample, regular_normal_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Extra Credit) Problem 2\n",
    "\n",
    "Consider a control variate for the problem above. The large pool model assumes that the portfolio is a large homogeneous pool, using the average default rate: $\\bar p = \\frac{1}{n}\\sum_i p_i$. Then the portfolio loss conditioned on market factor $z$ under the large pool model is a determinsitic scalar:\n",
    "\n",
    "$$ l(z) = (1-r)\\Phi\\left(\\frac{\\Phi^{-1}(\\bar p) - \\sqrt \\rho z}{\\sqrt{1-\\rho}}\\right)$$\n",
    "\n",
    "where $r$ is the constant recovery of all names. $\\Phi()$ is the normal CDF function; $\\Phi^{-1}()$ is its inverse. The tranche PVs can then be computed from the $l(z)$.\n",
    "\n",
    "Please investigate if the large pool model can be used as an effective control variate. Does it work better for some tranches?\n",
    "\n",
    "Hint: to answer this question, you only need to compute the correlation between the actual and control variates. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
