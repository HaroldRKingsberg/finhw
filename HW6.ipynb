{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import math\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import jit ## requires numba packages, you need to install it for this HW\n",
    "from scipy.stats import norm\n",
    "from numpy.random import rand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Extra Credit) Problem 1\n",
    "\n",
    "Python is an interpretive language, however, there are tools that can compile Python code on the fly and allows almost native execution speed in some cases. One of such tools is the numba just im time (JIT) compiler. The following is an implementation of the fast inverse normal CDF function, which can be used to convert uniform random numbers to normal random numbers. Note the @jit declaration in the code, which activates the numba JIT compiler for the following python function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ltqnorm( p ):\n",
    "    \"\"\"\n",
    "    Modified from the author's original perl code (original comments follow below)\n",
    "    by dfield@yahoo-inc.com.  May 3, 2004.\n",
    "\n",
    "    Lower tail quantile for standard normal distribution function.\n",
    "\n",
    "    This function returns an approximation of the inverse cumulative\n",
    "    standard normal distribution function.  I.e., given P, it returns\n",
    "    an approximation to the X satisfying P = Pr{Z <= X} where Z is a\n",
    "    random variable from the standard normal distribution.\n",
    "\n",
    "    The algorithm uses a minimax approximation by rational functions\n",
    "    and the result has a relative error whose absolute value is less\n",
    "    than 1.15e-9.\n",
    "\n",
    "    Author:      Peter John Acklam\n",
    "    Time-stamp:  2000-07-19 18:26:14\n",
    "    E-mail:      pjacklam@online.no\n",
    "    WWW URL:     http://home.online.no/~pjacklam\n",
    "    \"\"\"\n",
    "\n",
    "    if p <= 0 or p >= 1:\n",
    "        return np.nan\n",
    "\n",
    "    # Coefficients in rational approximations.\n",
    "    a = (-3.969683028665376e+01,  2.209460984245205e+02, \\\n",
    "         -2.759285104469687e+02,  1.383577518672690e+02, \\\n",
    "         -3.066479806614716e+01,  2.506628277459239e+00)\n",
    "    b = (-5.447609879822406e+01,  1.615858368580409e+02, \\\n",
    "         -1.556989798598866e+02,  6.680131188771972e+01, \\\n",
    "         -1.328068155288572e+01 )\n",
    "    c = (-7.784894002430293e-03, -3.223964580411365e-01, \\\n",
    "         -2.400758277161838e+00, -2.549732539343734e+00, \\\n",
    "          4.374664141464968e+00,  2.938163982698783e+00)\n",
    "    d = ( 7.784695709041462e-03,  3.224671290700398e-01, \\\n",
    "          2.445134137142996e+00,  3.754408661907416e+00)\n",
    "\n",
    "    # Define break-points.\n",
    "    plow  = 0.02425\n",
    "    phigh = 1 - plow\n",
    "\n",
    "    # Rational approximation for lower region:\n",
    "    if p < plow:\n",
    "       q  = math.sqrt(-2*math.log(p))\n",
    "       return (((((c[0]*q+c[1])*q+c[2])*q+c[3])*q+c[4])*q+c[5]) / \\\n",
    "               ((((d[0]*q+d[1])*q+d[2])*q+d[3])*q+1)\n",
    "\n",
    "    # Rational approximation for upper region:\n",
    "    if phigh < p:\n",
    "       q  = math.sqrt(-2*math.log(1-p))\n",
    "       return -(((((c[0]*q+c[1])*q+c[2])*q+c[3])*q+c[4])*q+c[5]) / \\\n",
    "                ((((d[0]*q+d[1])*q+d[2])*q+d[3])*q+1)\n",
    "\n",
    "    # Rational approximation for central region:\n",
    "    q = p - 0.5\n",
    "    r = q*q\n",
    "    return (((((a[0]*r+a[1])*r+a[2])*r+a[3])*r+a[4])*r+a[5])*q / \\\n",
    "           (((((b[0]*r+b[1])*r+b[2])*r+b[3])*r+b[4])*r+1)\n",
    "    \n",
    "\n",
    "\n",
    "ltqnorm_compiled = jit(ltqnorm)\n",
    "\n",
    "\n",
    "@jit\n",
    "def ninv_vec_compiled(xs) :\n",
    "    return np.array(list(map(ltqnorm_compiled, xs)))\n",
    "\n",
    "def ninv_vec(xs):\n",
    "    return np.array(list(map(ltqnorm, xs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1\n",
    "Use the above code to inverse 1 million equally sampled numbers btw 0 and 1, compare it with the build in `scipy.stats.norm.ppf` function to verify that the absolute error is on the order of $10^{-9}$. Is there a different btw the first run and the subsequent runs with the `@jit` flag on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time to Run (s)</th>\n",
       "      <th>Absolute Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.474422</td>\n",
       "      <td>5.610097e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.285472</td>\n",
       "      <td>5.284497e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.285240</td>\n",
       "      <td>5.520165e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.273741</td>\n",
       "      <td>5.522420e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.281243</td>\n",
       "      <td>5.619823e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time to Run (s)  Absolute Error\n",
       "0         0.474422    5.610097e-09\n",
       "1         0.285472    5.284497e-09\n",
       "2         0.285240    5.520165e-09\n",
       "3         0.273741    5.522420e-09\n",
       "4         0.281243    5.619823e-09"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def getdelta(d1, d2):\n",
    "    delta = d2 - d1\n",
    "    return delta.seconds + delta.microseconds*1e-6\n",
    "\n",
    "\n",
    "times = []\n",
    "errors = []\n",
    "\n",
    "for _ in range(5):\n",
    "    random_numbers = rand(int(1e6))\n",
    "    d1 = datetime.datetime.now()\n",
    "    calc = ninv_vec_compiled(random_numbers)\n",
    "    d2 = datetime.datetime.now()\n",
    "\n",
    "    errors.append(np.abs(calc - norm.ppf(random_numbers)).max())\n",
    "    times.append(getdelta(d1, d2))\n",
    "\n",
    "pd.DataFrame(np.array([times, errors]).T, columns=['Time to Run (s)', 'Absolute Error'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the first run of the function takes slightly less than twice the time of subsequent runs. This makes sense: just-in-time compilation occurs when a function is called, so the comparative length of the first call includes the compilation time, something the other calls would not have to deal with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "Remove the `@git` flag, and repeat 1, note the speed difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time to Run (s)</th>\n",
       "      <th>Absolute Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.841394</td>\n",
       "      <td>5.612179e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.226364</td>\n",
       "      <td>5.306116e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.962360</td>\n",
       "      <td>5.618047e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.892146</td>\n",
       "      <td>5.565546e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.010380</td>\n",
       "      <td>4.744154e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time to Run (s)  Absolute Error\n",
       "0         3.841394    5.612179e-09\n",
       "1         4.226364    5.306116e-09\n",
       "2         3.962360    5.618047e-09\n",
       "3         3.892146    5.565546e-09\n",
       "4         4.010380    4.744154e-09"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times = []\n",
    "errors = []\n",
    "\n",
    "for _ in range(5):\n",
    "    random_numbers = rand(int(1e6))\n",
    "    d1 = datetime.datetime.now()\n",
    "    calc = ninv_vec(random_numbers)\n",
    "    d2 = datetime.datetime.now()\n",
    "\n",
    "    errors.append(np.abs(calc - norm.ppf(random_numbers)).max())\n",
    "    times.append(getdelta(d1, d2))\n",
    "\n",
    "pd.DataFrame(np.array([times, errors]).T, columns=['Time to Run (s)', 'Absolute Error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It now takes roughly an order of magnitude more time to run, and subsequent runs are no faster than the initial. This is unsurprising."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "This problem explores the expoential log Euler and the Milstein scheme on the following CIR process:\n",
    "\n",
    "$$ d r(t) = \\kappa (\\bar{r} - r(t)) dt + \\sigma \\sqrt{r(t)} dw(t)$$\n",
    "\n",
    "with: $\\kappa = 0.1, \\bar{r} = 0.03, \\sigma = 0.05, r(0) = 0.01$, all the parameters are annualized.\n",
    "\n",
    "It was taught in many text book that when sampling the above CIR process, one way to avoid the negative value is to flip the sign of the random normal random number if it would lead to negative $r$ values in the next simulation step. This makes the $r(t)=0$ a reflective boundary.\n",
    "\n",
    "1. what is the analytical expression of  $\\mathbb E [r(t)]$, you can cite a reference to answer this question, but it is useful for you to understand how it was derived (no need to write it in your answers).\n",
    "2. implement the Euler discretizaitaon with the reflective boundary, run the simulation to compute the average of $r(10Y)$ with reflective boundary using different time sample step sizes, and plot the bias at 10Y as a function of the time sample step sizes.\n",
    "3. repeat 2, but using the log Euler sampling and comment on your results\n",
    "4. repeat, but use the Milstein scheme\n",
    "4. draw a few paths from all three methods using the same set random numbers and show that they are indeed path-wise equivalent for paths that do not hit zero (path wise equivalence guaranteed by Ito's lemma); also show a few paths that have different behaviours near $r(t) = 0$.\n",
    "\n",
    "Hint: in the log Euler step, the log(r(t)) can become very negative, leading to a underflow to 0. in the exp() function. You can apply a reflective cap/floor on the log(r(t)) to avoid the under flow problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "\n",
    "Consider two dimensional OU processes:\n",
    "\n",
    "$$\\begin{array} {l}\n",
    "d x(t) &= \\kappa_x (\\mu_x - x(t)) dt + \\sigma_x dw_x(t) \\\\\n",
    "d y(t) &= \\kappa_y (\\mu_y - y(t)) dt + \\sigma_y dw_y(t) \\\\\n",
    "\\end{array}$$\n",
    "\n",
    "with the following parameterization: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kx, ux, volx = .5, .05, .05\n",
    "ky, uy, voly = .1, .02, .01\n",
    "rho_xy = .5 # correlation between dw_x and dw_y\n",
    "x0, y0 = .01, .01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. simulate the correlated process to 1Y using Euler discretization, using 100 time steps, i.e., $dt = 0.01$. Estimate the correlation between the final values of $x(t=1Y), y(t=1Y)$. Is the simulated correlation the same as the correlation between $dw_x, dw_y$? \n",
    "3. [optional] derive the analytical formula for the correlation between the terminal value of $x(t)$ and $y(t)$, and verify it with the numerical simulation results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Extra Credit) Problem 4\n",
    "\n",
    "Price a American call option using LSMC, assuming:\n",
    "* initial stock price and option strikes: $s(0) = k = 100$\n",
    "* continuounsly compounded discount rate $r = 0.02$\n",
    "* continuous dividend yield is $y = 0.1$\n",
    "* stock volatility $\\sigma = 0.25$\n",
    "* option expiry: $t = 1Y$\n",
    "\n",
    "You need to produce the following output:\n",
    "1. European and American option prices\n",
    "2. Exercise boundary\n",
    "\n",
    "For this exercise, obviously you should not use the mc package provided as part of the lecture, you need to implement you own Americal LSMC pricer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
